{"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"import os","metadata":{},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"%env PINECONE_API_KEY=067e3580-67d3-4571-925f\n%set_env PINECONE_ENV=us-west4-gcp-free\n%set_env OPENAI_API_KEY=sk-Ap4eUfnLQOn7fZfVRAOST3B","metadata":{},"execution_count":2,"outputs":[{"name":"stdout","output_type":"stream","text":"env: PINECONE_API_KEY=067e3580-67d3-4571-925f-d058bb88cad4\n\nenv: PINECONE_ENV=us-west4-gcp-free\n\nenv: OPENAI_API_KEY=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\n"}]},{"cell_type":"code","source":"from dotenv import load_dotenv, find_dotenv","metadata":{},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"load_dotenv(find_dotenv())","metadata":{},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":["False"]},"metadata":{}}]},{"cell_type":"code","source":"from langchain.llms import OpenAI\nllm=OpenAI(model_name=\"text-davinci-003\")\nllm(\"explain large language models in one sentence\")","metadata":{"scrolled":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":["'\\n\\nLarge language models are machine learning models that use large amounts of text data to generate statistical models of language that can be used for natural language processing tasks.'"]},"metadata":{}}]},{"cell_type":"code","source":"from langchain.schema import (\n    AIMessage,\n    HumanMessage,\n    SystemMessage\n)\nfrom langchain.chat_models import ChatOpenAI","metadata":{},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"chat=ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.3)\nmessages = [\n    SystemMessage(content=\"you are a professional data scientist\"),\n    HumanMessage(content=\"Write a python script that trains a neural network on simulated data\")\n]\nresponse=chat(messages)","metadata":{},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"response","metadata":{},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":["AIMessage(content=\"Sure! Here's an example of a Python script that trains a simple neural network on simulated data using the Keras library:\\n\\n```python\\nimport numpy as np\\nfrom keras.models import Sequential\\nfrom keras.layers import Dense\\n\\n# Generate simulated data\\nnp.random.seed(0)\\nX = np.random.rand(1000, 2)\\ny = np.random.randint(2, size=(1000, 1))\\n\\n# Define the neural network architecture\\nmodel = Sequential()\\nmodel.add(Dense(10, input_dim=2, activation='relu'))\\nmodel.add(Dense(1, activation='sigmoid'))\\n\\n# Compile the model\\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\\n\\n# Train the model\\nmodel.fit(X, y, epochs=10, batch_size=32)\\n\\n# Evaluate the model\\nloss, accuracy = model.evaluate(X, y)\\nprint(f'Loss: {loss}, Accuracy: {accuracy}')\\n```\\n\\nIn this script, we first generate simulated data using `numpy.random.rand` and `numpy.random.randint`. We then define the neural network architecture using the `Sequential` model from Keras. The model consists of two dense layers, one with 10 neurons and ReLU activation, and the other with 1 neuron and sigmoid activation.\\n\\nAfter defining the model, we compile it using the binary cross-entropy loss function and the Adam optimizer. We then train the model using the `fit` method, specifying the number of epochs and batch size.\\n\\nFinally, we evaluate the trained model on the same data and print the loss and accuracy.\", additional_kwargs={}, example=False)"]},"metadata":{}}]},{"cell_type":"markdown","source":"# Prompts","metadata":{}},{"cell_type":"code","source":"import numpy as np\nfrom keras.models import Sequential\nfrom keras.layers import Dense\n# Generate simulated data\nnp.random.seed(0)\nX = np.random.rand(1000, 2)\ny = np.random.randint(2, size=(1000, 1))\n# Define the neural network architecture\nmodel = Sequential()\nmodel.add(Dense(10, input_dim=2, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\n#Compile the model\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n# Train the model\nmodel.fit(X, y, epochs=10, batch_size=32)\n# Evaluate the model\nloss, accuracy = model.evaluate(X, y)\nprint(f'Loss: {loss}, Accuracy: {accuracy}')\n\"\"\"In this script, we first generate simulated data using `numpy.random.rand` and `numpy.random.randint`.\nWe then define the neural network architecture using the `Sequential` model from Keras.\nThe model consists of two dense layers, one with 10 neurons and ReLU activation, and the other with \n1 neuron and sigmoid activation.\nAfter defining the model, we compile it using the binary cross-entropy loss function and the Adam optimizer.\nWe then train the model using the `fit` method, specifying the number of epochs and batch size.\nFinally, we evaluate the trained model on the same data and print the loss and accuracy.\"\"\"","metadata":{},"execution_count":17,"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'keras'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[1;32mIn[17], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dense\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Generate simulated data\u001b[39;00m\n","\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras'"]}]},{"cell_type":"code","source":"from langchain import PromptTemplate\ntemplate=\"\"\"\nyou are an expert data scientist with an expertise in building deep learning models.\nexplain the concept of {concept} in a couple of lines\"\"\"\nprompt=PromptTemplate(\n    input_variables=[\"concept\"], template=template)","metadata":{},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"prompt","metadata":{},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":["PromptTemplate(input_variables=['concept'], output_parser=None, partial_variables={}, template='\\nyou are an expert data scientist with an expertise in building deep learning models.\\nexplain the concept of {concept} in a couple of lines', template_format='f-string', validate_template=True)"]},"metadata":{}}]},{"cell_type":"code","source":"llm(prompt.format(concept=\"regularization\"))","metadata":{},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":["'\\n\\nRegularization is a technique used to reduce the complexity of a model by adding a penalty term to the loss function. This penalty term, usually referred to as a regularizer, constrains the model from overfitting, helping to improve its generalization performance on unseen data.'"]},"metadata":{}}]},{"cell_type":"code","source":"llm(prompt.format(concept=\"tuning\"))","metadata":{},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":["'\\n\\nTuning is the process of adjusting and optimizing hyperparameters in a machine learning model in order to find the best combination of parameters that yields the highest performance. This process requires an understanding of the data and the model, as well as the ability to evaluate and interpret the results of different combinations.'"]},"metadata":{}}]},{"cell_type":"markdown","source":"## Chain\nA chain takes a language model and a prompt and combines them into an interface that takes input from the user and output from the model. we can also have sequential chain. Sort of like an encoder, decoder system","metadata":{}},{"cell_type":"code","source":"from langchain.chains import LLMChain\nchain=LLMChain(llm=llm,prompt=prompt)\nchain.run(\"tuning\")","metadata":{},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":["'\\n\\nTuning is the process of adjusting the parameters of a model to achieve the best possible performance on a given task. It involves optimizing the hyperparameters of the model, such as the learning rate, number of layers, and number of neurons, to achieve the best results on a given dataset.'"]},"metadata":{}}]},{"cell_type":"markdown","source":"### Sequential chain","metadata":{}},{"cell_type":"code","source":"second_prompt= PromptTemplate(\n    input_variables=[\"ml_concept\"],\n    template=\"Turn the concept description of {ml_concept} and explain it like I am five in 500 words\",\n    )\nchain_two=LLMChain(llm=llm, prompt=second_prompt)","metadata":{},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"from langchain.chains import SimpleSequentialChain\noverall_chain= SimpleSequentialChain(chains=[chain,chain_two], verbose= True)\n\nexplanation= overall_chain.run(\"tuning\")\nexplanation","metadata":{},"execution_count":24,"outputs":[{"name":"stdout","output_type":"stream","text":"\n\n\n\n\u001b[1m> Entering new  chain...\u001b[0m\n\n\u001b[36;1m\u001b[1;3m\n\n\n\nTuning is the process of adjusting hyperparameters in a machine learning model to optimize its performance. This involves selecting the most suitable values of hyperparameters such as learning rate, regularization, and optimization algorithms to achieve the best results. Tuning is an essential part of any machine learning model building process and can significantly improve the accuracy of the model.\u001b[0m\n\n\u001b[33;1m\u001b[1;3m\n\n\n\nTuning a machine learning model is like a game of chess. It's all about finding the right moves to make it work better. Just like in chess, you have to think carefully about which pieces to move and when to move them. In machine learning, the pieces are called hyperparameters, and they control how the model works. \n\n\n\nA hyperparameter is like a setting that you can adjust to get the best results from your model. For example, if you’re trying to build a model that can recognize different types of animals in pictures, you might want to adjust the learning rate. This is the speed at which the model learns from the data you give it. If the learning rate is too high, the model might miss important details. If the learning rate is too low, the model might take too long to learn. \n\n\n\nTuning involves finding the best values of the hyperparameters to get the best results from your model. You can do this by testing different combinations of values and seeing which ones work best. You might also adjust the regularization, which is the amount of error the model is allowed to make. The optimization algorithm is another hyperparameter you can adjust. This algorithm controls how the model finds the\u001b[0m\n\n\n\n\u001b[1m> Finished chain.\u001b[0m\n"},{"execution_count":24,"output_type":"execute_result","data":{"text/plain":["\"\\n\\nTuning a machine learning model is like a game of chess. It's all about finding the right moves to make it work better. Just like in chess, you have to think carefully about which pieces to move and when to move them. In machine learning, the pieces are called hyperparameters, and they control how the model works. \\n\\nA hyperparameter is like a setting that you can adjust to get the best results from your model. For example, if you’re trying to build a model that can recognize different types of animals in pictures, you might want to adjust the learning rate. This is the speed at which the model learns from the data you give it. If the learning rate is too high, the model might miss important details. If the learning rate is too low, the model might take too long to learn. \\n\\nTuning involves finding the best values of the hyperparameters to get the best results from your model. You can do this by testing different combinations of values and seeing which ones work best. You might also adjust the regularization, which is the amount of error the model is allowed to make. The optimization algorithm is another hyperparameter you can adjust. This algorithm controls how the model finds the\""]},"metadata":{}}]},{"cell_type":"markdown","source":"### Embeddings and vectors\nSplit the answers into chunks to save in pinecone","metadata":{}},{"cell_type":"code","source":"from langchain.text_splitter import RecursiveCharacterTextSplitter\n\ntext_splitter=RecursiveCharacterTextSplitter(\nchunk_size=100,\nchunk_overlap=0)\ntexts=text_splitter.create_documents([explanation])","metadata":{},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"texts","metadata":{},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":["[Document(page_content=\"Tuning a machine learning model is like a game of chess. It's all about finding the right moves to\", metadata={}),\n"," Document(page_content='make it work better. Just like in chess, you have to think carefully about which pieces to move and', metadata={}),\n"," Document(page_content='when to move them. In machine learning, the pieces are called hyperparameters, and they control how', metadata={}),\n"," Document(page_content='the model works.', metadata={}),\n"," Document(page_content='A hyperparameter is like a setting that you can adjust to get the best results from your model. For', metadata={}),\n"," Document(page_content='example, if you’re trying to build a model that can recognize different types of animals in', metadata={}),\n"," Document(page_content='pictures, you might want to adjust the learning rate. This is the speed at which the model learns', metadata={}),\n"," Document(page_content='from the data you give it. If the learning rate is too high, the model might miss important', metadata={}),\n"," Document(page_content='details. If the learning rate is too low, the model might take too long to learn.', metadata={}),\n"," Document(page_content='Tuning involves finding the best values of the hyperparameters to get the best results from your', metadata={}),\n"," Document(page_content='model. You can do this by testing different combinations of values and seeing which ones work best.', metadata={}),\n"," Document(page_content='You might also adjust the regularization, which is the amount of error the model is allowed to', metadata={}),\n"," Document(page_content='make. The optimization algorithm is another hyperparameter you can adjust. This algorithm controls', metadata={}),\n"," Document(page_content='how the model finds the', metadata={})]"]},"metadata":{}}]},{"cell_type":"code","source":"texts[0].page_content","metadata":{},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":["\"Tuning a machine learning model is like a game of chess. It's all about finding the right moves to\""]},"metadata":{}}]},{"cell_type":"code","source":"from langchain.embeddings import OpenAIEmbeddings\nembeddings=OpenAIEmbeddings()","metadata":{},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"query_result=embeddings.embed_query(texts[0].page_content)\nquery_result","metadata":{},"execution_count":34,"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":["[-0.01581728830933571,\n"," -0.005575560033321381,\n"," 0.027002468705177307,\n"," -0.0006799152470193803,\n"," -0.03392338380217552,\n"," 0.02529948763549328,\n"," -0.026852605864405632,\n"," -0.030708156526088715,\n"," -0.011723321862518787,\n"," -0.04136200621724129,\n"," 0.006406615022569895,\n"," 0.00815387349575758,\n"," -0.010122519917786121,\n"," -0.007384126074612141,\n"," 0.0022445290815085173,\n"," 0.012063918635249138,\n"," -0.0012023047311231494,\n"," 0.00876694731414318,\n"," -0.011539400555193424,\n"," -0.03375989943742752,\n"," -0.030817147344350815,\n"," 0.0010933139128610492,\n"," 0.003438318846747279,\n"," -0.02096710354089737,\n"," -0.006219286937266588,\n"," 0.0030585541389882565,\n"," 0.009979469701647758,\n"," -0.01983632519841194,\n"," -0.016975315287709236,\n"," 0.01270423922687769,\n"," 0.013719215989112854,\n"," -0.006198851391673088,\n"," -0.0027247697580605745,\n"," -0.01912788487970829,\n"," -0.010040776804089546,\n"," 0.0002032933698501438,\n"," -0.02083086594939232,\n"," -0.005449539516121149,\n"," 0.00959119014441967,\n"," -0.00937320850789547,\n"," 0.027206826955080032,\n"," 0.007179768290370703,\n"," -0.009836419485509396,\n"," -0.0016638125525787473,\n"," 0.018651049584150314,\n"," 0.008678391575813293,\n"," -0.006668874062597752,\n"," 0.002765641314908862,\n"," -0.01644398644566536,\n"," -0.00544613366946578,\n"," -0.016893573105335236,\n"," 0.0473565012216568,\n"," -0.027738157659769058,\n"," -0.002459104871377349,\n"," 0.0007088658749125898,\n"," -0.015095224604010582,\n"," 0.0013794146943837404,\n"," 0.0021713010501116514,\n"," -0.007983575575053692,\n"," -0.003722716821357608,\n"," -9.499441512161866e-05,\n"," 0.0061307321302592754,\n"," -0.010980822145938873,\n"," 0.01677095890045166,\n"," 0.01089226733893156,\n"," -0.007833713665604591,\n"," 0.006692715920507908,\n"," 0.018923526629805565,\n"," 0.013896326534450054,\n"," -0.01671646349132061,\n"," 0.03318769484758377,\n"," 0.019087012857198715,\n"," -0.01633499562740326,\n"," 0.012506693601608276,\n"," 0.004666168242692947,\n"," -0.016675591468811035,\n"," -0.006222693249583244,\n"," -0.016784582287073135,\n"," 0.020681003108620644,\n"," 0.022561093792319298,\n"," 0.039754390716552734,\n"," -0.016239628195762634,\n"," -0.02809237688779831,\n"," -0.0029018798377364874,\n"," 0.027220450341701508,\n"," -0.01931861788034439,\n"," 0.01961834356188774,\n"," 0.0052111223340034485,\n"," -0.002319460269063711,\n"," 0.02080361731350422,\n"," 0.04787420481443405,\n"," 0.0025629866868257523,\n"," 0.009659308940172195,\n"," 0.005888908635824919,\n"," -0.010142955929040909,\n"," 0.01595352776348591,\n"," 0.002387579530477524,\n"," 0.027479304000735283,\n"," 0.001791536109521985,\n"," -0.019032517448067665,\n"," 0.03923668712377548,\n"," 0.013351372443139553,\n"," -0.03912769630551338,\n"," -0.0036818452645093203,\n"," -0.035122282803058624,\n"," -0.010830960236489773,\n"," -0.011648391373455524,\n"," -0.0020589041523635387,\n"," 0.013753275386989117,\n"," -0.02121233381330967,\n"," -0.020926231518387794,\n"," 0.031198615208268166,\n"," 0.008201557211577892,\n"," -0.03324219211935997,\n"," 0.0005355875473469496,\n"," 0.010790088213980198,\n"," -0.009502634406089783,\n"," -0.0011043832637369633,\n"," -0.027506550773978233,\n"," -0.0006620339117944241,\n"," 0.02074912190437317,\n"," 0.022302240133285522,\n"," 0.01319469790905714,\n"," 0.0014100683620199561,\n"," 0.00438347365707159,\n"," 0.0031164553947746754,\n"," -0.031580083072185516,\n"," -0.01101488247513771,\n"," -0.002276885788887739,\n"," -0.0008949165930971503,\n"," 0.030353935435414314,\n"," -0.01696169190108776,\n"," 0.008051695302128792,\n"," 0.02592618577182293,\n"," -0.027506550773978233,\n"," -0.00017189465870615095,\n"," 0.0008795897592790425,\n"," 0.0038180837873369455,\n"," -0.023201415315270424,\n"," -0.015272335149347782,\n"," 0.0016399708110839128,\n"," 0.03209779039025307,\n"," -0.01890990324318409,\n"," 0.018024353310465813,\n"," -0.01806522347033024,\n"," 0.005909344647079706,\n"," 0.018242333084344864,\n"," 0.022070635110139847,\n"," -0.00788139645010233,\n"," 0.005170250777155161,\n"," -0.01595352776348591,\n"," -0.022724580019712448,\n"," 0.01324919331818819,\n"," 0.013760088011622429,\n"," 0.027629166841506958,\n"," 0.007574860006570816,\n"," 0.01433228887617588,\n"," 0.0034298039972782135,\n"," -0.015258710831403732,\n"," -0.0052111223340034485,\n"," 0.003831707639619708,\n"," -0.00265835365280509,\n"," -0.004935239441692829,\n"," -0.0039475103840231895,\n"," 0.01734315976500511,\n"," 0.009509447030723095,\n"," 0.024768156930804253,\n"," 0.014713756740093231,\n"," 0.009945410303771496,\n"," 0.008760134689509869,\n"," 0.011805064976215363,\n"," 0.006089860573410988,\n"," -0.011008069850504398,\n"," 0.02880081720650196,\n"," -0.0015352375339716673,\n"," 0.022343112155795097,\n"," 0.03828301653265953,\n"," 0.013794147409498692,\n"," -0.01105575356632471,\n"," 0.00019648144370876253,\n"," -0.004049689043313265,\n"," 0.035694483667612076,\n"," 0.03741108998656273,\n"," 0.009747863747179508,\n"," 0.003654597559943795,\n"," -0.002035062527284026,\n"," -0.009625249542295933,\n"," 0.004053094889968634,\n"," -0.014768252149224281,\n"," -0.007138896733522415,\n"," 0.01836494915187359,\n"," 0.004339195787906647,\n"," -0.011191992089152336,\n"," 0.010817335918545723,\n"," -0.6068607568740845,\n"," -0.010183827020227909,\n"," 0.02202976495027542,\n"," 0.005023794248700142,\n"," 0.017561141401529312,\n"," 0.034931547939777374,\n"," 0.016784582287073135,\n"," -0.02606242336332798,\n"," -0.013603413477540016,\n"," -0.003852143418043852,\n"," -0.03689338266849518,\n"," -0.00022223903215490282,\n"," -0.008228804916143417,\n"," -0.016866324469447136,\n"," -0.00542569812387228,\n"," -0.020653754472732544,\n"," 0.04305136203765869,\n"," -0.040081363171339035,\n"," -0.05365071818232536,\n"," 0.007683850824832916,\n"," -0.018037976697087288,\n"," 0.02869182638823986,\n"," -0.020095176994800568,\n"," 0.013174261897802353,\n"," 0.008889561519026756,\n"," -0.01817421428859234,\n"," -0.00482284277677536,\n"," -0.010830960236489773,\n"," 0.008746511302888393,\n"," -0.0033208131790161133,\n"," -0.018037976697087288,\n"," 0.027002468705177307,\n"," -0.009509447030723095,\n"," 0.007642979267984629,\n"," 0.040789805352687836,\n"," 0.016076141968369484,\n"," -0.03239751234650612,\n"," 0.017997104674577713,\n"," 0.012608872726559639,\n"," 0.035748980939388275,\n"," -0.018405819311738014,\n"," -0.02170279249548912,\n"," 0.022969810292124748,\n"," -0.009386831894516945,\n"," 0.00027588295051828027,\n"," 0.010374560952186584,\n"," -0.010817335918545723,\n"," -0.0014177317498251796,\n"," 0.013392243534326553,\n"," -0.029373018071055412,\n"," 0.006249940954148769,\n"," -0.007057154085487127,\n"," 0.01847393997013569,\n"," 0.00692772725597024,\n"," 0.0005743303918279707,\n"," -0.02885531261563301,\n"," 0.012302335351705551,\n"," -0.008828254416584969,\n"," 0.04095328971743584,\n"," -0.005251993890851736,\n"," 0.019413985311985016,\n"," 0.012009423226118088,\n"," -0.03722035512328148,\n"," 0.0005257954471744597,\n"," -0.03730209916830063,\n"," 0.0234602689743042,\n"," 0.031171366572380066,\n"," 0.016212379559874535,\n"," -0.016403114423155785,\n"," -0.008855502121150494,\n"," -0.01581728830933571,\n"," 0.029318522661924362,\n"," 0.003405962372198701,\n"," -0.008794195018708706,\n"," 0.0025306299794465303,\n"," 0.023065175861120224,\n"," 0.014305041171610355,\n"," -0.008998552337288857,\n"," -0.006287406198680401,\n"," 0.01734315976500511,\n"," 0.020490268245339394,\n"," -0.005388232413679361,\n"," -0.017751876264810562,\n"," -0.030789898708462715,\n"," 0.030299440026283264,\n"," -0.008405914530158043,\n"," -0.0117301344871521,\n"," -0.03926393389701843,\n"," -0.003906638827174902,\n"," 0.009986281394958496,\n"," 0.020681003108620644,\n"," 0.023664625361561775,\n"," 0.015027105808258057,\n"," -0.014795499853789806,\n"," 0.012125225737690926,\n"," -0.014550270512700081,\n"," -0.009502634406089783,\n"," -0.0003084524651058018,\n"," 0.02828311175107956,\n"," -0.024182332679629326,\n"," -0.02885531261563301,\n"," -0.006144355982542038,\n"," 0.02633490040898323,\n"," 0.01034731324762106,\n"," -0.002663462422788143,\n"," 0.01698894053697586,\n"," 0.008460409939289093,\n"," 0.01304483599960804,\n"," 0.022642837837338448,\n"," -0.012329583056271076,\n"," -0.008072130382061005,\n"," -0.03487705439329147,\n"," -0.020408526062965393,\n"," 0.013283252716064453,\n"," 0.02164829708635807,\n"," -0.025640083476901054,\n"," 0.004965892992913723,\n"," 0.01652572862803936,\n"," 0.01323556900024414,\n"," -0.0481194369494915,\n"," 0.021225957199931145,\n"," -0.016975315287709236,\n"," -0.010749217122793198,\n"," 0.006771053187549114,\n"," 0.0013087410479784012,\n"," 0.027492927387356758,\n"," 0.020653754472732544,\n"," -0.013691968284547329,\n"," -0.008324171416461468,\n"," -0.0237599927932024,\n"," 0.00588550278916955,\n"," -0.01067428570240736,\n"," 0.012438573874533176,\n"," -0.02134857140481472,\n"," 0.041007786989212036,\n"," 0.00112907646689564,\n"," 0.011389537714421749,\n"," 0.011348666623234749,\n"," -0.013508046045899391,\n"," -0.00941407959908247,\n"," -0.013392243534326553,\n"," -0.027383936569094658,\n"," 0.00957756582647562,\n"," 0.003654597559943795,\n"," 0.009979469701647758,\n"," -0.02606242336332798,\n"," 0.004053094889968634,\n"," -0.024822652339935303,\n"," -0.0234330203384161,\n"," 0.002656650496646762,\n"," 0.004141650162637234,\n"," -0.0004555474442895502,\n"," 0.0010899079497903585,\n"," 0.005613025743514299,\n"," 0.00407693674787879,\n"," -0.03697512671351433,\n"," -0.017356783151626587,\n"," -0.00959119014441967,\n"," -0.01461839023977518,\n"," -0.04141649976372719,\n"," 0.0019516163738444448,\n"," 0.015790041536092758,\n"," -0.030299440026283264,\n"," 0.027438431978225708,\n"," -0.014809124171733856,\n"," -0.054086681455373764,\n"," -0.02584444172680378,\n"," 0.012104789726436138,\n"," -0.03288797289133072,\n"," -0.023691873997449875,\n"," 0.024740910157561302,\n"," -0.022574717178940773,\n"," -0.007520364597439766,\n"," 0.025558341294527054,\n"," -0.010313253849744797,\n"," 0.0064168330281972885,\n"," -0.01671646349132061,\n"," -0.0005130230565555394,\n"," -0.015027105808258057,\n"," -0.0032816447783261538,\n"," -0.012533941306173801,\n"," -0.010320065543055534,\n"," -0.00980917178094387,\n"," -0.010503987781703472,\n"," 0.00597405806183815,\n"," 0.002307539340108633,\n"," 0.023228662088513374,\n"," 0.02072187513113022,\n"," -0.03226127475500107,\n"," 0.019958939403295517,\n"," 0.0003097296867053956,\n"," 0.02622590959072113,\n"," 0.0020061118993908167,\n"," 0.003491111332550645,\n"," 0.03403237462043762,\n"," 0.0032799416221678257,\n"," 0.0006160534103401005,\n"," -0.008848690427839756,\n"," -0.0076225437223911285,\n"," -0.005977463908493519,\n"," 0.006784677039831877,\n"," 0.0035864782985299826,\n"," 0.010538047179579735,\n"," -0.03239751234650612,\n"," 0.002631105948239565,\n"," -0.040435582399368286,\n"," 0.026130542159080505,\n"," -0.027479304000735283,\n"," 0.008814630098640919,\n"," 0.0016587036661803722,\n"," 0.008855502121150494,\n"," -0.049972277134656906,\n"," -0.0018375166691839695,\n"," -0.018487563356757164,\n"," 0.026784487068653107,\n"," 0.025231368839740753,\n"," -0.012063918635249138,\n"," 0.025027010589838028,\n"," -0.008719263598322868,\n"," 0.00831735972315073,\n"," 0.008617084473371506,\n"," -0.011873184703290462,\n"," 0.05029924958944321,\n"," -0.0005947661702521145,\n"," 0.017520269379019737,\n"," 0.027888018637895584,\n"," -0.02359650656580925,\n"," -0.004942051135003567,\n"," 0.03266999125480652,\n"," -0.008467222563922405,\n"," -0.013201509602367878,\n"," -0.01444127969443798,\n"," 0.0032424761448055506,\n"," 0.020122425630688667,\n"," 0.03362365812063217,\n"," -0.03269723802804947,\n"," 0.004346007946878672,\n"," -0.0011094922665506601,\n"," 0.01630774699151516,\n"," -0.005347360856831074,\n"," 0.00849447026848793,\n"," 0.004543553572148085,\n"," -0.00012900082219857723,\n"," -0.02918228507041931,\n"," -0.0016433767741546035,\n"," -0.00460486114025116,\n"," 0.040571823716163635,\n"," -0.0013674938818439841,\n"," -0.0028593053575605154,\n"," 0.035367511212825775,\n"," -0.050163011997938156,\n"," -0.010599354282021523,\n"," -0.009931785985827446,\n"," -0.006631408352404833,\n"," 0.008637520484626293,\n"," -0.012745111249387264,\n"," -0.00015071383677423,\n"," 0.0053507667034864426,\n"," 0.031334854662418365,\n"," 0.024509305134415627,\n"," 0.009093919768929482,\n"," 0.03367815539240837,\n"," -0.011212428100407124,\n"," -0.0122069688513875,\n"," -0.004942051135003567,\n"," -0.035231273621320724,\n"," 0.0014994748635217547,\n"," -0.04160723462700844,\n"," -0.0017395952017977834,\n"," 0.03948191553354263,\n"," -0.0071048373356461525,\n"," -0.01281323004513979,\n"," 0.020503893494606018,\n"," -0.009277841076254845,\n"," 0.02194802090525627,\n"," 0.0005577263073064387,\n"," 0.004158679861575365,\n"," 0.011845936998724937,\n"," 0.0018647643737494946,\n"," 0.016621096059679985,\n"," 0.01396444533020258,\n"," -0.027302194386720657,\n"," 0.04130750894546509,\n"," 0.00853534135967493,\n"," -0.004567395430058241,\n"," -0.015149720013141632,\n"," -0.04207044467329979,\n"," 0.0012099681189283729,\n"," -0.018146967515349388,\n"," -0.010027153417468071,\n"," -0.0033122983295470476,\n"," 0.011818689294159412,\n"," -0.003356575733050704,\n"," -0.01858293078839779,\n"," -0.01828320510685444,\n"," -0.0012687209527939558,\n"," 0.045394666492938995,\n"," -0.006784677039831877,\n"," 0.0016093171434476972,\n"," 0.00035422007204033434,\n"," -0.01063341461122036,\n"," 0.02581719495356083,\n"," -0.02912778966128826,\n"," -0.04098053649067879,\n"," 0.04182521626353264,\n"," 0.03702962026000023,\n"," -0.012356830760836601,\n"," -0.027506550773978233,\n"," 0.006893667858093977,\n"," -0.01581728830933571,\n"," 0.009584377519786358,\n"," 0.0020640131551772356,\n"," 0.007581672165542841,\n"," -0.00908710714429617,\n"," -0.015490316785871983,\n"," 0.016103390604257584,\n"," 0.00948219932615757,\n"," 0.00019520420755725354,\n"," 0.026675496250391006,\n"," 0.039890632033348083,\n"," -0.012697427533566952,\n"," -0.01728866435587406,\n"," -0.022043388336896896,\n"," 0.0019175567431375384,\n"," 0.05656622350215912,\n"," 0.03291521966457367,\n"," -0.013072083704173565,\n"," 0.0028814440593123436,\n"," -0.02803788147866726,\n"," 0.017629260197281837,\n"," -0.0231332965195179,\n"," -0.004100778605788946,\n"," 0.009162038564682007,\n"," 0.010933139361441135,\n"," -0.012329583056271076,\n"," 0.015245087444782257,\n"," 0.007547612302005291,\n"," 0.009993093088269234,\n"," -0.0059399981983006,\n"," 0.01912788487970829,\n"," -0.009550318121910095,\n"," -0.015108848921954632,\n"," -0.03427760303020477,\n"," -0.007642979267984629,\n"," -0.0028269486501812935,\n"," 0.03392338380217552,\n"," -0.0032578029204159975,\n"," -0.003525170963257551,\n"," -0.0025374419055879116,\n"," 0.03253374993801117,\n"," -0.009495822712779045,\n"," 0.019277745857834816,\n"," 0.010749217122793198,\n"," -0.05040824040770531,\n"," -0.007172956597059965,\n"," 0.02175728790462017,\n"," -0.009931785985827446,\n"," 0.026321277022361755,\n"," -0.03405962139368057,\n"," 0.035449255257844925,\n"," 0.006454298738390207,\n"," 0.015408573672175407,\n"," 0.001382820657454431,\n"," -0.02384173683822155,\n"," 0.02192077413201332,\n"," 0.0115530239418149,\n"," -0.00800401158630848,\n"," -0.0059331865049898624,\n"," 0.012336395680904388,\n"," -0.01847393997013569,\n"," 0.012472634203732014,\n"," 0.016948068514466286,\n"," 0.01839219592511654,\n"," -0.035639990121126175,\n"," 0.025776322931051254,\n"," 0.001614426146261394,\n"," -0.045285675674676895,\n"," 0.009788735769689083,\n"," 0.0018375166691839695,\n"," 0.0119889872148633,\n"," -0.031035128980875015,\n"," 0.00350814126431942,\n"," 0.0006160534103401005,\n"," -0.02340577356517315,\n"," -0.008916809223592281,\n"," -0.027247698977589607,\n"," -0.0009672932792454958,\n"," -0.0237599927932024,\n"," 0.008828254416584969,\n"," 0.014931738376617432,\n"," -0.02638939581811428,\n"," -0.02904604561626911,\n"," -0.0021661920472979546,\n"," -0.000984323094598949,\n"," -0.04296962171792984,\n"," -0.03316044807434082,\n"," -0.02855558693408966,\n"," -0.005711798556149006,\n"," 0.03798329085111618,\n"," 0.016239628195762634,\n"," 0.014822747558355331,\n"," -0.020898984745144844,\n"," -0.011457657441496849,\n"," 0.013480798341333866,\n"," -0.0021116966381669044,\n"," -0.003995193634182215,\n"," -0.017138801515102386,\n"," -0.008583025075495243,\n"," 0.009747863747179508,\n"," -0.02096710354089737,\n"," -0.008739699609577656,\n"," 0.0027894831728190184,\n"," -0.00533714285120368,\n"," -0.016975315287709236,\n"," -0.0017557735554873943,\n"," -0.0004255324020050466,\n"," 0.015285958535969257,\n"," -0.019550222903490067,\n"," -0.011028505861759186,\n"," 0.005251993890851736,\n"," 0.00716614443808794,\n"," 0.002062310231849551,\n"," -0.0007744306931272149,\n"," -0.02069462649524212,\n"," 0.002098072785884142,\n"," 0.00024884811136871576,\n"," -0.018514810130000114,\n"," -0.0017234169645234942,\n"," -0.00522815203294158,\n"," -0.01085139624774456,\n"," 0.02061288431286812,\n"," -0.004795595072209835,\n"," -0.0044890581630170345,\n"," -0.0236782506108284,\n"," 0.04231567680835724,\n"," 0.008814630098640919,\n"," 0.005275835748761892,\n"," 0.0008174309623427689,\n"," 0.01029281783849001,\n"," 0.0035660425201058388,\n"," 0.01707068271934986,\n"," -0.010068024508655071,\n"," -0.00864433217793703,\n"," 0.0229970570653677,\n"," 0.012602060101926327,\n"," -0.01576279290020466,\n"," 0.02145756222307682,\n"," -0.012261464260518551,\n"," -0.022547470405697823,\n"," -0.02416870929300785,\n"," 0.004454998765140772,\n"," 0.0027264729142189026,\n"," 0.003749964525923133,\n"," 0.007738346233963966,\n"," -0.017547518014907837,\n"," 0.018078848719596863,\n"," -0.006481546442955732,\n"," -0.013296877034008503,\n"," -0.029454762116074562,\n"," -0.029590999707579613,\n"," -0.003995193634182215,\n"," 0.009584377519786358,\n"," -0.00946857500821352,\n"," -0.0007872030255384743,\n"," -0.013944009318947792,\n"," 0.008051695302128792,\n"," 0.002958078170195222,\n"," -0.01641673780977726,\n"," 0.0237872414290905,\n"," -0.04384154826402664,\n"," -0.01293584518134594,\n"," 0.014318665489554405,\n"," 0.022166002541780472,\n"," 0.04226117953658104,\n"," 0.005102131515741348,\n"," 0.015994399785995483,\n"," -0.02630765177309513,\n"," -0.02861008234322071,\n"," 0.0026924132835119963,\n"," -0.027520176023244858,\n"," 0.0010013529099524021,\n"," 0.015081601217389107,\n"," 0.012452198192477226,\n"," 0.04340558499097824,\n"," 0.02655288204550743,\n"," -0.004012223798781633,\n"," -0.011157932691276073,\n"," 0.020653754472732544,\n"," 0.008201557211577892,\n"," -0.0032935654744505882,\n"," 0.014918114989995956,\n"," -0.006532635539770126,\n"," -0.0073636905290186405,\n"," 0.001555673312395811,\n"," 0.029618248343467712,\n"," -0.026838982477784157,\n"," 0.02102159895002842,\n"," 0.003228852292522788,\n"," 0.012370455078780651,\n"," 0.01434591319411993,\n"," -0.008950868621468544,\n"," -0.02219325117766857,\n"," -0.03403237462043762,\n"," -0.03670264780521393,\n"," -0.0026396207977086306,\n"," -0.010858207941055298,\n"," 0.008896373212337494,\n"," 0.006665468215942383,\n"," -0.03893696144223213,\n"," 0.0054086679592728615,\n"," 0.021253203973174095,\n"," 0.023691873997449875,\n"," 0.017670132219791412,\n"," 0.02219325117766857,\n"," 0.015027105808258057,\n"," -0.02877356857061386,\n"," 0.0020742309279739857,\n"," -0.013378620147705078,\n"," 0.012302335351705551,\n"," 0.009625249542295933,\n"," -0.01709793135523796,\n"," -0.048991359770298004,\n"," 0.015463069081306458,\n"," 0.011709698475897312,\n"," 0.015694674104452133,\n"," 0.016784582287073135,\n"," 0.004066718742251396,\n"," -0.0012661664513871074,\n"," -0.012213780544698238,\n"," 0.01888265460729599,\n"," -0.016757333651185036,\n"," -0.024332193657755852,\n"," -0.021443938836455345,\n"," -0.03850099816918373,\n"," -0.020898984745144844,\n"," -0.007023094221949577,\n"," 0.018146967515349388,\n"," -0.012554377317428589,\n"," 0.029454762116074562,\n"," 0.01052442379295826,\n"," 0.003760182298719883,\n"," 0.02576269954442978,\n"," -0.03444109112024307,\n"," -0.017384031787514687,\n"," 0.021634671837091446,\n"," -0.006709745619446039,\n"," 0.025776322931051254,\n"," 0.0025578776840120554,\n"," 0.026430267840623856,\n"," 0.026130542159080505,\n"," -0.001038818503729999,\n"," 0.0004772604734171182,\n"," -0.00015454554522875696,\n"," 0.009236969985067844,\n"," 0.0007169550517573953,\n"," 0.00473428750410676,\n"," 0.013106143102049828,\n"," 0.0006032810779288411,\n"," -0.006239722948521376,\n"," -0.00826286431401968,\n"," -0.031580083072185516,\n"," -0.01877366378903389,\n"," -0.013187886215746403,\n"," -0.009332336485385895,\n"," 0.010272381827235222,\n"," -0.01817421428859234,\n"," -0.017656508833169937,\n"," -0.01731591299176216,\n"," -0.007159332744777203,\n"," 0.04738374799489975,\n"," -0.00291550369001925,\n"," 0.020898984745144844,\n"," 0.014727381058037281,\n"," -0.021934397518634796,\n"," -0.006876637693494558,\n"," 0.03239751234650612,\n"," -0.009557129815220833,\n"," 0.030517421662807465,\n"," 0.0002997246920131147,\n"," -0.013671532273292542,\n"," 0.0005875285132788122,\n"," 0.00701628252863884,\n"," 0.004533336032181978,\n"," -0.007751970086246729,\n"," 0.007322818972170353,\n"," 0.03613044694066048,\n"," -0.017247792333364487,\n"," 0.0026941162068396807,\n"," -0.0008663916378282011,\n"," 0.00391345052048564,\n"," 0.007404562085866928,\n"," -0.015081601217389107,\n"," -0.007213828153908253,\n"," 0.02828311175107956,\n"," -0.02619866281747818,\n"," -0.006495170295238495,\n"," -0.004104184452444315,\n"," -0.015681050717830658,\n"," 0.011130684986710548,\n"," -0.017819995060563087,\n"," -0.022751828655600548,\n"," -0.0012091166572645307,\n"," -0.029400266706943512,\n"," -0.01704343594610691,\n"," 0.029155036434531212,\n"," 0.0032373671419918537,\n"," -0.017465773969888687,\n"," -0.00703671807423234,\n"," -0.008896373212337494,\n"," -0.024413937702775,\n"," -0.008882749825716019,\n"," 0.01461839023977518,\n"," 0.01926412247121334,\n"," -0.03367815539240837,\n"," -0.03207053989171982,\n"," -0.01323556900024414,\n"," 0.005623243749141693,\n"," -0.001404959475621581,\n"," 0.03820127248764038,\n"," -0.04269714280962944,\n"," -0.008528529666364193,\n"," 0.054985854774713516,\n"," -0.027315817773342133,\n"," 0.03803778812289238,\n"," -0.02576269954442978,\n"," -0.012636120431125164,\n"," -0.008950868621468544,\n"," 0.005415480118244886,\n"," -0.009066672064363956,\n"," -0.008453598245978355,\n"," 0.004928427282720804,\n"," -0.03397788107395172,\n"," -0.0004717257688753307,\n"," -0.015340453945100307,\n"," -0.004223393276333809,\n"," 0.019250499084591866,\n"," 0.02576269954442978,\n"," -0.02540847845375538,\n"," -0.012854102067649364,\n"," 0.030599165707826614,\n"," -0.01416880264878273,\n"," -0.012077542021870613,\n"," -0.025081505998969078,\n"," 0.008249240927398205,\n"," 0.008528529666364193,\n"," -0.011757382191717625,\n"," 0.02529948763549328,\n"," -0.016266874969005585,\n"," 0.015694674104452133,\n"," -0.013453550636768341,\n"," 0.03272448480129242,\n"," -0.0034349130000919104,\n"," -0.034795310348272324,\n"," 0.0004380918981041759,\n"," -0.025040633976459503,\n"," 0.04367806017398834,\n"," -0.02069462649524212,\n"," 0.005848037078976631,\n"," 0.020054306834936142,\n"," 0.001371751306578517,\n"," -0.003729528747498989,\n"," 0.006897073704749346,\n"," 0.012390891090035439,\n"," -0.007499929051846266,\n"," -0.007969952188432217,\n"," 0.002680492354556918,\n"," 0.011335042305290699,\n"," 0.0004402206395752728,\n"," -0.011151120066642761,\n"," -0.005333737004548311,\n"," -0.01940036192536354,\n"," -0.013174261897802353,\n"," -0.026048799976706505,\n"," -0.0054972232319414616,\n"," -0.00782690104097128,\n"," 0.02638939581811428,\n"," 0.01899164542555809,\n"," -0.05095319449901581,\n"," -0.02792889066040516,\n"," 0.0052111223340034485,\n"," -0.04223393276333809,\n"," -0.017111554741859436,\n"," -0.01866467297077179,\n"," 0.01753389462828636,\n"," 0.001479890663176775,\n"," 0.005360984709113836,\n"," -0.012615684419870377,\n"," 0.03335118293762207,\n"," -0.009441327303647995,\n"," 0.008487657643854618,\n"," -0.003361684735864401,\n"," -0.01072878111153841,\n"," -0.0037363406736403704,\n"," -0.00979554746299982,\n"," 0.0004589534073602408,\n"," -0.005657303147017956,\n"," -0.02869182638823986,\n"," -0.0067880828864872456,\n"," 0.017329536378383636,\n"," -0.0017268229275941849,\n"," -0.0028984739910811186,\n"," -0.012581625021994114,\n"," 0.005030606407672167,\n"," -0.005401856265962124,\n"," 0.0002296895836479962,\n"," -0.004587830975651741,\n"," -0.0025459567550569773,\n"," -0.014550270512700081,\n"," 0.0012985231587663293,\n"," -0.02053114026784897,\n"," -0.0044107213616371155,\n"," 0.022397607564926147,\n"," -0.022928938269615173,\n"," -0.02175728790462017,\n"," 8.206240454455838e-05,\n"," 0.022670084610581398,\n"," 0.002184924902394414,\n"," -0.02858283556997776,\n"," -0.026212286204099655,\n"," -0.0016740304417908192,\n"," 0.007745158392935991,\n"," -0.006127326283603907,\n"," 0.04411402344703674,\n"," 0.004700228106230497,\n"," -0.003957728389650583,\n"," -0.005136190913617611,\n"," 0.0027452055364847183,\n"," -0.01600802317261696,\n"," -0.005057854112237692,\n"," 0.005347360856831074,\n"," -0.01945485733449459,\n"," 0.004271076526492834,\n"," 0.006362337619066238,\n"," -0.00716614443808794,\n"," 0.0026549475733190775,\n"," 0.023555634543299675,\n"," 0.023310406133532524,\n"," -0.0009613328729756176,\n"," -0.017275040969252586,\n"," -0.017792746424674988,\n"," -0.00698222266510129,\n"," -0.02091260813176632,\n"," 0.026294028386473656,\n"," 0.01855568215250969,\n"," -0.024713661521673203,\n"," -0.0023313811980187893,\n"," 0.007465869188308716,\n"," -0.004478840623050928,\n"," -0.015231463126838207,\n"," -0.020108802244067192,\n"," 0.01422329805791378,\n"," -0.023773616179823875,\n"," 0.01277235895395279,\n"," -0.01598077453672886,\n"," 0.0014756331220269203,\n"," -0.02666187286376953,\n"," 0.00024735802435316145,\n"," 0.004914803430438042,\n"," -0.02806513011455536,\n"," 0.0008625599439255893,\n"," 0.1835404932498932,\n"," -0.01847393997013569,\n"," -0.009025800041854382,\n"," 0.003249288070946932,\n"," 0.029972467571496964,\n"," 0.0030738809145987034,\n"," 0.02833760529756546,\n"," 0.004315354395657778,\n"," -0.01720692217350006,\n"," -0.009965845383703709,\n"," 0.006100078579038382,\n"," -0.001242324709892273,\n"," -0.0021747068967670202,\n"," 0.008187932893633842,\n"," 0.004346007946878672,\n"," -0.01737040840089321,\n"," -0.035585492849349976,\n"," -0.021934397518634796,\n"," -0.010020340792834759,\n"," 0.01380095910280943,\n"," 0.03885521739721298,\n"," 0.018760040402412415,\n"," -0.008405914530158043,\n"," -0.01880091242492199,\n"," 0.035776227712631226,\n"," 0.011995798908174038,\n"," 0.024700038135051727,\n"," 0.013719215989112854,\n"," 0.013835018500685692,\n"," -0.008467222563922405,\n"," -0.03272448480129242,\n"," 0.0044618104584515095,\n"," -0.008596648462116718,\n"," 0.012350019067525864,\n"," -0.005745858419686556,\n"," 0.0020759340841323137,\n"," -0.002797998022288084,\n"," -0.026130542159080505,\n"," 0.01576279290020466,\n"," 0.01674371026456356,\n"," 0.02649838663637638,\n"," -0.013351372443139553,\n"," -0.0026396207977086306,\n"," -0.020285911858081818,\n"," -0.0023381931241601706,\n"," 0.03422310948371887,\n"," ...]"]},"metadata":{}}]},{"cell_type":"code","source":"import pinecone\nfrom langchain.vectorstores import Pinecone\n#Initialize pinecone\npinecone.init(\napi_key=os.getenv('PINECONE_API_KEY'),\nenvironment=os.getenv('PINECONE_ENV')\n)\n","metadata":{},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"pip install tiktoken","metadata":{},"execution_count":41,"outputs":[{"name":"stdout","output_type":"stream","text":"Collecting tiktoken\n\n  Downloading tiktoken-0.4.0-cp310-cp310-win_amd64.whl (635 kB)\n\n     ------------------------------------ 635.3/635.3 kB 261.5 kB/s eta 0:00:00\n\nRequirement already satisfied: regex>=2022.1.18 in c:\\users\\pc\\appdata\\local\\anaconda3\\lib\\site-packages (from tiktoken) (2022.7.9)\n\nRequirement already satisfied: requests>=2.26.0 in c:\\users\\pc\\appdata\\local\\anaconda3\\lib\\site-packages (from tiktoken) (2.28.1)\n\nRequirement already satisfied: certifi>=2017.4.17 in c:\\users\\pc\\appdata\\local\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2023.5.7)\n\nRequirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\pc\\appdata\\local\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2.0.4)\n\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\pc\\appdata\\local\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken) (1.26.14)\n\nRequirement already satisfied: idna<4,>=2.5 in c:\\users\\pc\\appdata\\local\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.4)\n\nInstalling collected packages: tiktoken\n\nSuccessfully installed tiktoken-0.4.0\n\nNote: you may need to restart the kernel to use updated packages.\n"}]},{"cell_type":"code","source":"search = Pinecone.from_documents(texts, embeddings, index_name=\"lanchain\")","metadata":{},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"query=\"what can i adjust in tuning\"\nresult = search.similarity_search(query)","metadata":{},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"result","metadata":{},"execution_count":64,"outputs":[{"execution_count":64,"output_type":"execute_result","data":{"text/plain":["[Document(page_content='pictures, you might want to adjust the learning rate. This is the speed at which the model learns', metadata={}),\n"," Document(page_content='make. The optimization algorithm is another hyperparameter you can adjust. This algorithm controls', metadata={}),\n"," Document(page_content=\"Tuning a machine learning model is like a game of chess. It's all about finding the right moves to\", metadata={}),\n"," Document(page_content='Tuning involves finding the best values of the hyperparameters to get the best results from your', metadata={})]"]},"metadata":{}}]},{"cell_type":"markdown","source":"## Agent\nLike a code interpreter in this use case","metadata":{}},{"cell_type":"code","source":"from langchain.agents.agent_toolkits import create_python_agent\nfrom langchain.tools.python.tool import PythonREPLTool\nfrom langchain.python import PythonREPL\nfrom langchain.llms.openai import OpenAI","metadata":{},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"agent_executor = create_python_agent(\n    llm=OpenAI(temperature=0, max_tokens=1000),\n    tool=PythonREPLTool(),\n    verbose=True\n)","metadata":{},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"agent_executor.run(\"Find the roots(zeros) of the quadratic function 3* x**2 + 2*x -1\")","metadata":{},"execution_count":74,"outputs":[{"name":"stdout","output_type":"stream","text":"\n\n\n\n\u001b[1m> Entering new  chain...\u001b[0m\n\n\u001b[32;1m\u001b[1;3m I need to solve a quadratic equation\n\nAction: Python_REPL\n\nAction Input: import numpy as np\u001b[0m\n\nObservation: \u001b[36;1m\u001b[1;3m\u001b[0m\n\nThought:\u001b[32;1m\u001b[1;3m I can use numpy to solve the equation\n\nAction: Python_REPL\n\nAction Input: np.roots([3,2,-1])\u001b[0m\n\nObservation: \u001b[36;1m\u001b[1;3m\u001b[0m\n\nThought:\u001b[32;1m\u001b[1;3m I now know the final answer\n\nFinal Answer: The roots of the quadratic function are -1 and 0.33333\u001b[0m\n\n\n\n\u001b[1m> Finished chain.\u001b[0m\n"},{"execution_count":74,"output_type":"execute_result","data":{"text/plain":["'The roots of the quadratic function are -1 and 0.33333'"]},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}